{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/14/24 16:25:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Using                                                                  <a href=\"file://c:\\Users\\gufer\\miniconda3\\envs\\mtg_env\\Lib\\site-packages\\kedro\\framework\\project\\__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\gufer\\miniconda3\\envs\\mtg_env\\Lib\\site-packages\\kedro\\framework\\project\\__init__.py#249\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'c:\\Users\\gufer\\miniconda3\\envs\\mtg_env\\Lib\\site-packages\\kedro\\framew</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">ork\\project\\rich_logging.yml'</span> as logging configuration.                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/14/24 16:25:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using                                                                  \u001b]8;id=836886;file://c:\\Users\\gufer\\miniconda3\\envs\\mtg_env\\Lib\\site-packages\\kedro\\framework\\project\\__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=66710;file://c:\\Users\\gufer\\miniconda3\\envs\\mtg_env\\Lib\\site-packages\\kedro\\framework\\project\\__init__.py#249\u001b\\\u001b[2m249\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'c:\\Users\\gufer\\miniconda3\\envs\\mtg_env\\Lib\\site-packages\\kedro\\framew\u001b[0m \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32mork\\project\\rich_logging.yml'\u001b[0m as logging configuration.                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook current working directory: c:\\Users\\gufer\\OneDrive\\Documentos\\FIAP\\Fase_03\\notebooks\\gmferratti\\pipeline\n",
      "Project path: c:\\Users\\gufer\\OneDrive\\Documentos\\FIAP\\Fase_03\\mtg-project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kedro.framework.startup import bootstrap_project\n",
    "from kedro.framework.session import KedroSession\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Encontrar o caminho absoluto do diretório atual\n",
    "notebook_cwd = os.getcwd()\n",
    "\n",
    "# Definir o caminho para a raiz do projeto Kedro com base na estrutura de diretórios\n",
    "# Neste caso, navegamos 4 níveis acima até a raiz do projeto\n",
    "project_path = os.path.abspath(os.path.join(notebook_cwd, \"../../../mtg-project\"))\n",
    "\n",
    "# Verificar o diretório atual e o caminho do projeto\n",
    "print(f\"Notebook current working directory: {notebook_cwd}\")\n",
    "print(f\"Project path: {project_path}\")\n",
    "\n",
    "# Alterar para o diretório raiz do projeto Kedro\n",
    "os.chdir(project_path)\n",
    "\n",
    "# Bootstrap o projeto Kedro\n",
    "bootstrap_project(project_path)\n",
    "\n",
    "# Inicialize o contexto do Kedro\n",
    "with KedroSession.create() as session:\n",
    "    context = session.load_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso seja necessario recarregar, rodar esta celula\n",
    "from kedro.framework.session import KedroSession\n",
    "\n",
    "# Recarregar o contexto e o catálogo\n",
    "with KedroSession.create() as session:\n",
    "    context = session.load_context()\n",
    "\n",
    "# Recarregar o catálogo\n",
    "catalog = context.catalog\n",
    "\n",
    "# Acessa os parâmetros\n",
    "params = context.params\n",
    "\n",
    "catalog.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with KedroSession.create(env=\"local\", project_path=project_path) as session:\n",
    "    session.run(pipeline_name=\"webscraping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def setup_logger(logger_name:str, \n",
    "                 log_folder: str = None) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Configura o logger para salvar os logs em um arquivo ou exibi-los no terminal.\n",
    "    \n",
    "    Args:\n",
    "        log_folder (str, optional): Caminho do arquivo onde os logs serão salvos. \n",
    "        Se for None, o logger exibirá as informações no terminal.\n",
    "    \n",
    "    Returns:\n",
    "        logging.Logger: Logger configurado para salvar logs em arquivo ou exibi-los no terminal.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Desativa a propagação do logger para o logger raiz\n",
    "    logger.propagate = False\n",
    "\n",
    "    # Verifica se já existem handlers para evitar duplicação de logs\n",
    "    if not logger.hasHandlers():\n",
    "        if log_folder:\n",
    "            # Criar um handler para salvar o log em arquivo\n",
    "            file_handler = logging.FileHandler(log_folder, mode='w', encoding='utf-8')\n",
    "            file_handler.setLevel(logging.INFO)\n",
    "\n",
    "            # Criar um formato para o log\n",
    "            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "            file_handler.setFormatter(formatter)\n",
    "\n",
    "            # Adicionar o handler ao logger\n",
    "            logger.addHandler(file_handler)\n",
    "        else:\n",
    "            # Criar um StreamHandler para exibir os logs no terminal\n",
    "            console_handler = logging.StreamHandler()\n",
    "            console_handler.setLevel(logging.INFO)\n",
    "\n",
    "            # Criar um formato para o log no console\n",
    "            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "            console_handler.setFormatter(formatter)\n",
    "\n",
    "            # Adicionar o handler ao logger\n",
    "            logger.addHandler(console_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "def get_deck_zip_from_web(        \n",
    "        project_path: str,\n",
    "        zip_url: str,  \n",
    "        zip_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Baixa um arquivo ZIP de um URL, o descompacta em uma pasta temporária e salva os arquivos JSON\n",
    "    no subdiretório 'decks_json' dentro da pasta especificada.\n",
    "\n",
    "    Args:\n",
    "        project_path (str): Caminho base do projeto onde o zip_folder será concatenado.\n",
    "        zip_url (str): URL do arquivo ZIP a ser baixado.\n",
    "        zip_folder (str): Caminho relativo dentro do project_path onde o arquivo ZIP será salvo.\n",
    "\n",
    "    Returns:\n",
    "        None: A função salva os arquivos JSON na pasta especificada e não retorna nada.\n",
    "    \"\"\"\n",
    "    # Configura o logger geral com o nome \"get_deck_zip_logger\"\n",
    "    logger = setup_logger(\"get_deck_zip_logger\")\n",
    "\n",
    "    # Concatenar o caminho completo de zip_folder com project_path (que é a raiz)\n",
    "    full_output_path = os.path.join(project_path, zip_folder)\n",
    "    \n",
    "    # Criar a pasta raiz se ela não existir\n",
    "    os.makedirs(full_output_path, exist_ok=True)\n",
    "\n",
    "    # Criar o subdiretório 'decks_json' dentro da pasta especificada\n",
    "    decks_json_path = os.path.join(full_output_path, 'decks_json')\n",
    "    os.makedirs(decks_json_path, exist_ok=True)\n",
    "\n",
    "    # Função para baixar o arquivo zip\n",
    "    def download_file(url, folder):\n",
    "        local_filename = os.path.join(folder, url.split(\"/\")[-1])\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(local_filename, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        logger.info(f\"Zip dos decklists baixado com sucesso em: {local_filename}\")\n",
    "        return local_filename\n",
    "\n",
    "    # Baixar o arquivo zip\n",
    "    zip_file_path = download_file(zip_url, full_output_path)\n",
    "\n",
    "    # Descompactar o arquivo zip e salvar os arquivos JSON no subdiretório 'decks_json'\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.endswith('.json'):\n",
    "                # Definir o caminho de destino do arquivo extraído no subdiretório 'decks_json'\n",
    "                output_file_path = os.path.join(decks_json_path, file_name)\n",
    "                \n",
    "                # Ler e salvar o arquivo JSON diretamente no caminho especificado\n",
    "                with zip_ref.open(file_name) as json_file, open(output_file_path, \"wb\") as out_file:\n",
    "                    out_file.write(json_file.read())\n",
    "    \n",
    "    logger.info(f\"Arquivos JSON extraídos com sucesso em: {decks_json_path}\")\n",
    "\n",
    "    # Remover o arquivo zip após extração\n",
    "    os.remove(zip_file_path)\n",
    "    logger.info(f\"Arquivo ZIP removido após extração!\")\n",
    "\n",
    "    # Remover o handler para evitar problemas futuros\n",
    "    for handler in logger.handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "\n",
    "project_path = catalog.load(\"params:global.user.project_path\")\n",
    "zip_url = catalog.load(\"params:preprocessing.webscraper.zip_url\")\n",
    "zip_folder = catalog.load(\"params:preprocessing.webscraper.zip_folder\")\n",
    "\n",
    "get_deck_zip_from_web(project_path,zip_url, zip_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_decks_from_json_files(\n",
    "        decks_json_partitioned: dict, \n",
    "        deck_cards: int, \n",
    "        log_folder: str) -> dict:\n",
    "    \"\"\"\n",
    "    Processa todos os decks JSON fornecidos pelo PartitionedDataSet e salva no formato .txt.\n",
    "\n",
    "    Faz isso desde que contenham pelo menos o número mínimo de cartas definido em deck_cards (params).\n",
    "    O log dos decks processados é salvo em um arquivo no log_folder (params).\n",
    "\n",
    "    Args:\n",
    "        decks_json_partitioned (dict): Dicionário de decks carregados de arquivos JSON através de PartitionedDataSet.\n",
    "        deck_cards (int): Número mínimo de cartas no mainBoard para que o deck seja processado.\n",
    "        log_folder (str): Caminho do arquivo onde os logs serão salvos.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário de decks processados, onde as chaves são os nomes dos arquivos e os valores são as decklists.\n",
    "    \"\"\"\n",
    "    # Caminho do arquivo de log\n",
    "    log_filepath = os.path.join(log_folder, 'decks_selection_log.txt')\n",
    "\n",
    "    # Cria a pasta de log se ela não existir\n",
    "    os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "    # Chama a função para configurar o logger\n",
    "    logger = setup_logger(\"pp_decks_from_json_files\", log_filepath)\n",
    "\n",
    "    # Função para extrair o nome do deck diretamente do JSON\n",
    "    def get_deck_name(data):\n",
    "        return data['data'].get('name', 'Unknown Deck')\n",
    "\n",
    "    # Função para contar o número de cartas no mainBoard\n",
    "    def count_mainboard_cards(data):\n",
    "        return sum(card['count'] for card in data['data']['mainBoard'])\n",
    "\n",
    "    # Função para gerar a decklist formatada\n",
    "    def generate_decklist(data):\n",
    "        decklist = []\n",
    "        deck_name = get_deck_name(data)\n",
    "        decklist.append(\"About\")\n",
    "        decklist.append(f\"Name {deck_name}\")\n",
    "        decklist.append(\"\\nDeck\")\n",
    "\n",
    "        for card in data['data']['mainBoard']:\n",
    "            name = card['name']\n",
    "            count = card['count']\n",
    "            decklist.append(f\"{count} {name}\")\n",
    "\n",
    "        return decklist\n",
    "\n",
    "    # Dicionário de saída para armazenar as decklists processadas\n",
    "    processed_decks = {}\n",
    "\n",
    "    # Percorrer os arquivos JSON no dicionário fornecido pelo PartitionedDataSet\n",
    "    for file_name, dataset in decks_json_partitioned.items():\n",
    "        # Carregar os dados chamando o método `load()` do dataset\n",
    "        data = dataset()\n",
    "\n",
    "        # Verificar se o deck tem pelo menos deck_cards no mainboard\n",
    "        if count_mainboard_cards(data) >= deck_cards:\n",
    "            \n",
    "            # Gerar a decklist\n",
    "            decklist = generate_decklist(data)\n",
    "\n",
    "            # Definir o nome do arquivo de saída .txt com base no nome do deck\n",
    "            deck_name = get_deck_name(data)\n",
    "            output_file_name = f\"{deck_name.replace(' ', '_')}.txt\"\n",
    "\n",
    "            # Salvar no dicionário de decks processados\n",
    "            processed_decks[output_file_name] = \"\\n\".join(decklist)\n",
    "\n",
    "            logger.info(f\"Decklist {output_file_name} gerada com sucesso!\")\n",
    "        else:\n",
    "            logger.info(f\"Deck {file_name} ignorado (menos de {deck_cards} cartas no mainBoard).\")\n",
    "\n",
    "    # Remover o handler para evitar problemas futuros\n",
    "    for handler in logger.handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "    return processed_decks\n",
    "\n",
    "decks_json_partitioned = catalog.load(\"decks_json_partitioned\")\n",
    "deck_cards = catalog.load(\"params:preprocessing.webscraper.deck_cards\")\n",
    "log_folder = catalog.load(\"params:preprocessing.webscraper.log_folder\")\n",
    "\n",
    "txt_decks_dict = pp_decks_from_json_files(decks_json_partitioned, deck_cards, log_folder)\n",
    "txt_decks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a pasta artificialmente aqui (para evitar rodar o pipeline)\n",
    "output_folder = project_path + '/data/01_raw/decks_txt'\n",
    "\n",
    "# Criar a pasta caso ela não exista\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterar sobre o dicionário e salvar cada deck como um arquivo .txt\n",
    "for file_name, deck_content in txt_decks_dict.items():\n",
    "    # Caminho completo do arquivo de saída\n",
    "    output_file_path = os.path.join(output_folder, file_name)\n",
    "    \n",
    "    # Escrever o conteúdo do deck no arquivo .txt\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(deck_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_decks(\n",
    "        decks_txt_partitioned: dict, \n",
    "        sample_size: float, \n",
    "        log_folder: str) -> dict:\n",
    "    \"\"\"\n",
    "    Amostra os decks no formato .txt com base no sample_size e retorna um dicionário de paths.\n",
    "\n",
    "    Args:\n",
    "        decks_txt_partitioned (dict): Dicionário de decks onde as chaves são nomes de arquivos e os valores são funções que retornam o conteúdo do deck.\n",
    "        sample_size (float): A fração da população original que será usada para amostragem (valor entre 0 e 1).\n",
    "        log_folder (str): Caminho da pasta para salvar os logs.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário com os caminhos dos decks amostrados.\n",
    "    \"\"\"\n",
    "\n",
    "    # Caminho do arquivo de log\n",
    "    log_filepath = os.path.join(log_folder, 'decks_sampling_log.txt')\n",
    "\n",
    "    # Cria a pasta de log se ela não existir\n",
    "    os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "    # Configurar o logger para salvar no arquivo .txt\n",
    "    logger = setup_logger('decks_sampling_logger', log_filepath)\n",
    "\n",
    "    # Número total de decks disponíveis\n",
    "    total_decks = len(decks_txt_partitioned)\n",
    "    \n",
    "    # Calcular o tamanho da amostra\n",
    "    target_sample_size = int(total_decks * sample_size)\n",
    "\n",
    "    # Amostra aleatória da população\n",
    "    logger.info(f\"Amostrando {target_sample_size} decks de um total de {total_decks}.\")\n",
    "    sampled_keys = random.sample(list(decks_txt_partitioned.keys()), target_sample_size)\n",
    "    \n",
    "    # Criar dicionário contendo os paths dos decks amostrados\n",
    "    sampled_decks = {key: os.path.join('data/01_raw/decks_txt', key) for key in sampled_keys}\n",
    "\n",
    "    # Logar os decks escolhidos\n",
    "    logger.info(f\"Decks amostrados: {', '.join(sampled_keys)}\")\n",
    "    logger.info(f\"Amostragem completa. {len(sampled_decks)} decks selecionados.\")\n",
    "\n",
    "    return sampled_decks\n",
    "\n",
    "\n",
    "decks_txt = catalog.load(\"decks_txt_partitioned\")\n",
    "sample_size = catalog.load(\"params:preprocessing.webscraper.sample_size_ratio\")\n",
    "log_folder = catalog.load(\"params:preprocessing.webscraper.log_folder\")\n",
    "\n",
    "sample_decks_dict = sample_decks(decks_txt, sample_size, log_folder)\n",
    "catalog.save(\"sampled_decks\",sample_decks_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
